<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Quickstart with Deeplearning4J &#8211; dubs·tech</title>
<meta name="description" content="This blog post shows how to get started with DL4J in no time. By using an example where the goal is to predict whether a customer will leave his bank, each step of a typical workflow is considered.">
<meta name="keywords" content="dl4j, guide">

<!-- Twitter Cards -->
<meta name="twitter:card" content="summary">
<meta name="twitter:site" content="@dot_treo">
<meta name="twitter:creator" content="@dot_treo">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Quickstart with Deeplearning4J">
<meta property="og:description" content="This blog post shows how to get started with DL4J in no time. By using an example where the goal is to predict whether a customer will leave his bank, each step of a typical workflow is considered.">
<meta property="og:url" content="https://www.dubs.tech/guides/quickstart-with-dl4j/">
<meta property="og:site_name" content="dubs·tech">
<meta property="og:image" content="https://www.dubs.tech/images/images/logo.png">

<meta name="google-site-verification" content="n-ohWAcyARq2F3YAT0UtBa3gh0fluEoFMmHupOCXOvs">



<link rel="canonical" href="https://www.dubs.tech/guides/quickstart-with-dl4j/">
<link href="https://www.dubs.tech/feed.xml" type="application/atom+xml" rel="alternate" title="dubs·tech Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no"/>

<!-- For all browsers -->
<link rel="stylesheet" href="https://www.dubs.tech/assets/css/main.css">
<link rel="stylesheet" href="https://www.dubs.tech/assets/css/jquery.mmenu.all.css">
<link rel="stylesheet" href="https://www.dubs.tech/assets/css/jquery.floating-social-share.min.css">
<!-- Webfonts -->
<link href="https://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic" rel="stylesheet" type="text/css">

<meta http-equiv="cleartype" content="on">

<!-- Load Modernizr -->
<script type="text/javascript" src="https://www.dubs.tech/assets/js/vendor/modernizr-2.6.2.custom.min.js"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML">
</script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://www.dubs.tech/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://www.dubs.tech/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://www.dubs.tech/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://www.dubs.tech/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://www.dubs.tech/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://www.dubs.tech/images/apple-touch-icon-144x144-precomposed.png">




</head>

<body id="post" >

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->



<div class="header-menu header-menu-top">
    <ul class="header-item-container">
      <li class="header-item-title header-toggle "><a href="#menu"><h2><i class="fa fa-bars"></i></h2></a></li>
      <li class="header-item-title">
        <a href="https://www.dubs.tech/">
          
            <img class="logo" src="https://www.dubs.tech/images/logo.png" alt="dubs·tech">
          
          <a href="https://www.dubs.tech/" class="title"> dubs·tech</a>
        </a>
      </li>
      
        
        

        
          <li class="header-item "><a href="https://www.dubs.tech/categories"><h3>Categories</h3></a>
            <ul class="header-submenu">
              
                
                  <li class="sub-item"><a href="https://www.dubs.tech/categories/#blog">blog</a></li>
              
                
                  <li class="sub-item"><a href="https://www.dubs.tech/categories/#guides">guides</a></li>
              
            </ul>
          </li>
        
      
        
        

        
            
                <li class="header-item "><a href="https://www.dubs.tech/tags"><h3>Tags</h3></a></li>
            
        
      
        
        

        
            
                <li class="header-item "><a href="https://www.dubs.tech/"><h3>Home</h3></a></li>
            
        
      
      <li class="header-item"><a href="https://www.dubs.tech/search"><h3><i class="fa fa-search"></i></h3></a></li>
    </ul>
  </div>
<div class="entry-header">
  <div class="header-title">
    <div class="header-title-wrap">
      <h1>Quickstart with Deeplearning4J</h1>
      
        <h2><span class="entry-date date published updated"><time datetime="2018-08-06T11:43:27+02:00">August 06, 2018</time></span></h2>
      

      
        <p class="entry-reading-time">
          <i class="fa fa-clock-o"></i>
          
          Reading time ~30 minutes
        </p><!-- /.entry-reading-time -->
      
    </div><!-- /.header-title-wrap -->
  </div><!-- /.header-title -->
</div><!-- /.entry-header -->


<nav id="menu" style="display: none">
  <ul>
    
      
        <li><a href="https://www.dubs.tech/"><h3>Home</h3></a></li>
      
    
      
        <li><a href="https://www.dubs.tech/tags"><h3>Tags</h3></a></li>
      
    
      
        <li><a href="https://www.dubs.tech/categories"><h3>Categories</h3></a>
          <ul>
            
              
                <li><a href="https://www.dubs.tech/categories/#blog">blog</a></li>
            
              
                <li><a href="https://www.dubs.tech/categories/#guides">guides</a></li>
            
          </ul>
        </li>
      
    
  </ul>
</nav>

<div id="main" role="main">
  <article class="hentry">
    <div class="entry-content">
        
      <h1 class="post-title entry-title">Quickstart with Deeplearning4J</h1>
      <p>Deep learning, i.e. the use of deep, multi-layer neural networks, is the major driver of the current machine learning boom. From great leaps in quality in automatic translation, over autonomous driving, to beating grandmasters in the game Go, this technique has made a lot of headlines.</p>

<p>Deeplearning4J, also called DL4J, is a Java library for Deep Learning. But, it also a whole family of other libraries that simplify the use of deep learning models with Java. As an alternative to the many Python based frameworks, DL4J offers a way to easily bring Deep Learning into existing enterprise environments.</p>

<p>This blog post shows how to get started with DL4J in no time. By using an example where the goal is to predict whether a customer will leave his bank, each step of a typical workflow is considered. In order to focus on the individual steps, only excerpts of the code currently being discussed are shown. Imports and other Java boilerplate are left out, but the complete code including training data can be found at <a href="https://github.com/treo/quickstart-with-dl4j">https://github.com/treo/quickstart-with-dl4j</a>.</p>

<!--more-->

<p><em>Update 07.11.2018</em>: Version <code class="highlighter-rouge">1.0.0-beta3</code> has been released. I’ll update this post shortly. The model shown here needs to be retuned and the dependency declaration for ParallelInference needs to be updated. In the meantime check out the release notes for <a href="https://deeplearning4j.org/release-notes#onezerozerobeta3">Deeplearning4J 1.0.0-beta3</a>.</p>

<p><em>Update 20.02.2019</em>: Finally came around to updating this to use version <code class="highlighter-rouge">1.0.0-beta3</code>. Changed a few hyper parameters; Added some additional headings for the DataVec section; Updated <a href="https://github.com/treo/quickstart-with-dl4j">companion project</a> with the fixes necessary to run on Java 11.</p>

<ul id="markdown-toc">
  <li><a href="#integrating-dl4j-into-your-project" id="markdown-toc-integrating-dl4j-into-your-project">Integrating DL4J into your project</a></li>
  <li><a href="#loading-data" id="markdown-toc-loading-data">Loading data</a>    <ul>
      <li><a href="#datavec" id="markdown-toc-datavec">DataVec</a>        <ul>
          <li><a href="#defining-a-schema" id="markdown-toc-defining-a-schema">Defining a Schema</a></li>
          <li><a href="#analyzing-the-data" id="markdown-toc-analyzing-the-data">Analyzing the data</a></li>
          <li><a href="#transformation-and-normalization" id="markdown-toc-transformation-and-normalization">Transformation and Normalization</a></li>
          <li><a href="#vectorization" id="markdown-toc-vectorization">Vectorization</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#training-the-model" id="markdown-toc-training-the-model">Training the model</a>    <ul>
      <li><a href="#defining-the-structure" id="markdown-toc-defining-the-structure">Defining the structure</a></li>
      <li><a href="#training" id="markdown-toc-training">Training</a></li>
      <li><a href="#evaluation" id="markdown-toc-evaluation">Evaluation</a></li>
      <li><a href="#tuning" id="markdown-toc-tuning">Tuning</a></li>
      <li><a href="#saving" id="markdown-toc-saving">Saving</a></li>
    </ul>
  </li>
  <li><a href="#using-the-model" id="markdown-toc-using-the-model">Using the Model</a>    <ul>
      <li><a href="#parallel-inference" id="markdown-toc-parallel-inference">Parallel Inference</a></li>
    </ul>
  </li>
  <li><a href="#beyond-the-quickstart" id="markdown-toc-beyond-the-quickstart">Beyond the quickstart</a></li>
  <li><a href="#closing-remarks" id="markdown-toc-closing-remarks">Closing remarks</a></li>
</ul>

<h1 id="integrating-dl4j-into-your-project">Integrating DL4J into your project</h1>

<p>DL4J, like many other Java libraries, can easily be included as yet another dependency in the build tool of choice. In this post, the necessary information is given in Maven format, as it would be seen in a pom.xml file. Of course, you can also use another build tool like Gradle or SBT.</p>

<p>DL4J is not intended to be used without build tools, since it itself has a large number of direct and transitive dependencies. Therefore, there is no single jar file that you could manually specify as a dependency in your IDE.
DL4J and its libraries have a modular structure so that you can adapt its dependencies to the needs of your project. Especially for beginners this can make getting started a bit more complicated, because it is not necessarily obvious which submodule is needed to make a certain class available.</p>

<p>The used versions of all DL4J modules should always be the same. To simplify version management, we define a property which we will use in the following to specify the version. DL4J is currently close to its 1.0 release and in this post, we are using version 1.0.0-beta3, which has only recently been released.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;properties&gt;</span>
    <span class="nt">&lt;dl4j.version&gt;</span>1.0.0-beta3<span class="nt">&lt;/dl4j.version&gt;</span>
<span class="nt">&lt;/properties&gt;</span>
</code></pre></div></div>

<p>For the beginner it is advisable to start with the <code class="highlighter-rouge">deeplearning4j-core</code> module. It includes many other modules transitively and thus allows the use of a multitude of features without having to search for the right dependency. The disadvantage is that when bundling all dependencies into an Uberjar you will get a large file.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.deeplearning4j<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>deeplearning4j-core<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>${dl4j.version}<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>DL4J supports multiple backends, which allows the use of CPU or GPU. In the simplest case, the backend is selected by specifying a dependency. To use the CPU backend, <code class="highlighter-rouge">nd4j-native-platform</code> is required. For the GPU backend, <code class="highlighter-rouge">nd4j-cuda-X.Y-platform</code> is used, where X.Y should be replaced by the installed CUDA version. Currently CUDA 8.0, 9.0, 9.1 and 9.2 are supported.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.nd4j<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>nd4j-native-platform<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>${dl4j.version}<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>Both backends rely on the use of native binaries, which is why the platform modules also include the binaries for all supported platforms. This allows distributing an Uberjar to several different platforms without having to create a single specialized jar file for each one of them. The currently supported platforms for the CPU backend are: Linux (PPC64LE, x86_64), Windows (x86_64), macOS (x86_64), Android (ARM, ARM64, x86, x86_64); for CUDA-enabled GPUs: Linux (PPC64LE, x86_64), macOS (x86_64), Windows (x86_64).</p>

<p>Due to the fact that some of DL4J’s own dependencies are not yet fully compatible with newer Java versions, some workarounds can be required to make it run on Java 9/10/11 (see <a href="https://github.com/treo/quickstart-with-dl4j/blob/86162976fc7d7b74e1df62d0fa1fc32c25ea024b/pom.xml#L66-L79">pom.xml:66-79</a>)</p>

<p>As the last dependency for a basic setup, we add a logger. DL4J requires an SLF4J-API compatible logger to share its information with us. In this example we use Logback Classic.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>ch.qos.logback<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>logback-classic<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>${logback.version}<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>As can already be seen from the specification of the backend, ND4J forms the foundation on which DL4J builds. ND4J is a library for fast tensor math with Java. In order to make maximum use of the available hardware, practically all calculations are carried out outside the JVM. This way CPU features such as AVX vector instructions and GPUs can be utilized.</p>

<p>If a GPU is used, however, it should be known that for deep learning in particular, a quite potent GPU is often required to achieve a speed advantage over a CPU. This is especially true for notebook GPUs that were released before the current GeForce 1000 series, and even on the desktop you should at least have a GeForce GTX 960 with 4GB RAM. The reason for this recommendation is that GPUs shine especially with calculations on large amounts of data - but these large amounts of data also require a corresponding amount of RAM and this is only available in sufficient quantities with the more powerful models.</p>

<h1 id="loading-data">Loading data</h1>

<p>As with all other forms of Machine learning, in order to do any deep learning, data has to be collected and loaded first. This blog post focuses on tabular data available as CSV files. However, the procedure for other file formats, or other data types such as images, is similar.</p>

<p>Basically, if you want to get good results quickly, you should have a good understanding of your data and the problem to be solved. Some expert knowledge about the data and the general problem area, as well as an appropriate preparation of the data, can significantly reduce the model complexity and training time in many cases.</p>

<p>Another point to note is that you have to divide your data into at least two parts to train a model. Most of the data, usually about 80%, is used for training and is therefore referred to as the training set. The remaining data, usually around 20%, is used to evaluate the quality of the model and is referred to as the test set. Especially when more advanced tuning is required, it is also common to reserve another 10% of the training data for a validation set to check whether the model has been overfitted to the test set.</p>

<p>When selecting data for the test set, it should be noted that it should consist of a representative subset of all data. This is necessary to be able to check the informative value of the model properly. The same is true for the validation set in cases where it is used.</p>

<p>The <a href="https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling">data set</a> used in this blog post  comes from Kaggle, a platform for data science and machine learning competitions. It consists of tabular data and contains not only purely numerical but also categorical data. It has already been preprocessed somewhat and split into a training set and a test set.</p>

<figure class="center">
<img src="/images/quickstart-with-dl4j/data.PNG" />
</figure>

<p>The data set consists of a bank’s customer data. Each line represents a customer and, in the column “Exited” also contains the information whether the customer has left the bank. The problem we want to solve in this example is to train a model that can use this customer data to predict whether a customer will leave the bank. So, it is a classic classification problem with 2 classes: “Will remain customer” and “Will leave the bank”.</p>

<h2 id="datavec">DataVec</h2>

<p>Like all other statistical machine learning methods, deep learning only works with numerical data. DataVec is a DL4J library that supports us in loading, analyzing and converting our data into the necessary format. To use it, we do not need to specify another dependency, since it is already loaded as a transitive dependency of the <code class="highlighter-rouge">deeplearning4j-core</code> module.</p>

<p>In this example we will encounter the three core concepts of DataVec. These consist of the <code class="highlighter-rouge">InputSplit</code>, <code class="highlighter-rouge">RecordReader</code> and <code class="highlighter-rouge">TransformProccess</code>. They can be understood as the steps that the data must go through in order to be enriched from raw data to actually usable data.</p>

<figure class="center">
<img src="/images/quickstart-with-dl4j/datavec-steps.png" />
</figure>

<p>We start by creating a <code class="highlighter-rouge">FileSplit</code>. The task of the InputSplit will be to provide the RecordReader with a single input. We pass it the folder where our training set is located as a <code class="highlighter-rouge">File</code> instance, and an optional <code class="highlighter-rouge">Random</code> object. By providing that random object, <code class="highlighter-rouge">FileSplit</code> will read the files in a random order. This will become important later for training.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Random</span> <span class="n">random</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Random</span><span class="o">();</span>
<span class="n">random</span><span class="o">.</span><span class="na">setSeed</span><span class="o">(</span><span class="mh">0xC0FFEE</span><span class="o">);</span>
<span class="n">FileSplit</span> <span class="n">inputSplit</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FileSplit</span><span class="o">(</span><span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">"X:/Churn_Modelling/Train/"</span><span class="o">),</span> <span class="n">random</span><span class="o">);</span>
</code></pre></div></div>

<p>In addition to <code class="highlighter-rouge">FileSplit</code>, there are a number of other implementations of <code class="highlighter-rouge">InputSplit</code> that can provide data from an Input Stream or a Collection, for example.</p>

<p>Our data is CSV formatted, therefore we create a <code class="highlighter-rouge">CSVRecordReader</code> and initialize it with the previously created <code class="highlighter-rouge">InputSplit</code>. The <code class="highlighter-rouge">RecordReader</code> will then take the input it receives from the <code class="highlighter-rouge">InputSplit</code> and divide it into one or more examples. These examples can then be retrieved from the <code class="highlighter-rouge">RecordReader</code> in the form of records.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">CSVRecordReader</span> <span class="n">recordReader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">CSVRecordReader</span><span class="o">();</span>
<span class="n">recordReader</span><span class="o">.</span><span class="na">initialize</span><span class="o">(</span><span class="n">inputSplit</span><span class="o">);</span>
</code></pre></div></div>

<p>As with the <code class="highlighter-rouge">FileSplit</code>, DataVec also provides different implementations for the <code class="highlighter-rouge">RecordReader</code> interface, like readers for Excel files, pictures, videos or even (via JDBC connected) databases.</p>

<h3 id="defining-a-schema">Defining a Schema</h3>

<p>Records are basically nothing more than lists of values. And especially in the case of the <code class="highlighter-rouge">CSVRecordReader</code>, these values are all strings. In order to continue working with them, we have to define a schema for our data. Similar to the schema you may know from SQL databases, we specify here which types of values can be in a record. Due to the fact that a record is a list of values, we also have to pay attention to the order of the column definitions here, since it must correspond to the order in our CSV files.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Schema</span><span class="o">.</span><span class="na">Builder</span><span class="o">()</span>
                <span class="o">.</span><span class="na">addColumnsInteger</span><span class="o">(</span><span class="s">"Row Number"</span><span class="o">,</span> <span class="s">"Customer Id"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnString</span><span class="o">(</span><span class="s">"Surname"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnInteger</span><span class="o">(</span><span class="s">"Credit Score"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Geography"</span><span class="o">,</span> <span class="s">"France"</span><span class="o">,</span> <span class="s">"Germany"</span><span class="o">,</span> <span class="s">"Spain"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Gender"</span><span class="o">,</span> <span class="s">"Female"</span><span class="o">,</span> <span class="s">"Male"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnsInteger</span><span class="o">(</span><span class="s">"Age"</span><span class="o">,</span> <span class="s">"Tenure"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnDouble</span><span class="o">(</span><span class="s">"Balance"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnInteger</span><span class="o">(</span><span class="s">"Num Of Products"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Has Credit Card"</span><span class="o">,</span> <span class="s">"0"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Is Active Member"</span><span class="o">,</span> <span class="s">"0"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnDouble</span><span class="o">(</span><span class="s">"Estimated Salary"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Exited"</span><span class="o">,</span> <span class="s">"0"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre></div></div>

<p>Here it is already worthwhile to know your data at least superficially. For example, we have already specified all possible values for the “Geography” and “Gender” columns in the schema, and we have specified the numbers 0 and 1 for “Has Credit Card”, “Is Active Member” and “Exited” as categorical instead of declaring them as integers. This is because experience has shown that such yes/no information works better as categorical data (with one-hot encoding, see below).</p>

<h3 id="analyzing-the-data">Analyzing the data</h3>

<p>In the next step, we will first have the data analyzed. For this we use a new feature, called <code class="highlighter-rouge">AnalyzeLocal</code>, which is not made available by the <code class="highlighter-rouge">deeplearning4j-core</code> module and therefore requires us to add another dependency.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.datavec<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>datavec-local<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>${dl4j.version}<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>After adding the dependency, running the analysis is easy. We specify the <code class="highlighter-rouge">Schema</code> and <code class="highlighter-rouge">RecordReader</code> as parameters and get a result.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">DataAnalysis</span> <span class="n">analysis</span> <span class="o">=</span> <span class="n">AnalyzeLocal</span><span class="o">.</span><span class="na">analyze</span><span class="o">(</span><span class="n">schema</span><span class="o">,</span> <span class="n">recordReader</span><span class="o">);</span>
<span class="n">HtmlAnalysis</span><span class="o">.</span><span class="na">createHtmlAnalysisFile</span><span class="o">(</span><span class="n">analysis</span><span class="o">,</span> <span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">"X:/Churn_Modelling/analysis.html"</span><span class="o">));</span>
</code></pre></div></div>

<p>We can also output the result in human-readable form as an <a href="/images/quickstart-with-dl4j/analysis.html">HTML file</a>. With the help of the analysis output, we can get even more familiar with the data. For each column we get an evaluation of how its values are distributed and a histogram as a visualization of this distribution.</p>

<p>We pay particular attention to the value range of the numeric columns. For the training of neural networks, it is recommended that each input lies in a range between -1 and 1, otherwise you quickly leave the functional range of activation functions and regularization methods - the effect is that the model does not learn.</p>

<figure class="half">
<img src="/images/quickstart-with-dl4j/viz-age.PNG" />

<img src="/images/quickstart-with-dl4j/viz-tenure.png" />

<img src="/images/quickstart-with-dl4j/viz-creditscore.PNG" />

<img src="/images/quickstart-with-dl4j/viz-salary.PNG" />
</figure>

<p>We see that in many cases the value range lies outside the recommended -1 to 1 range. So, we will have to normalize this data before we can continue using it. However, in addition to normalization, there is also further preparatory work to be done.</p>

<h3 id="transformation-and-normalization">Transformation and Normalization</h3>

<p>Here we come to the last step before we can vectorize the data: the TransformProcess. We use it to implement what we have learned from the analysis. We start by removing the columns “Row Number”, “Customer Id” and “Surname”, as these seem useless for the problem and could lead to training problems down the road.</p>

<p>The columns, which we have classified as categorical right from the start, are now transformed into a one-hot encoding. This means that each category gets its own column. Each, but one, of those columns is set to 0. The one column that gets a 1 is exactly the column of the corresponding category. This type of encoding is always useful when you have data that does not have a natural translation into a numerical form and cannot be sorted. In our example it would make no sense to code the countries of the “Geography” column as <code class="highlighter-rouge">0,1,2</code>, since each country could assume any of these values. Instead, the “Geography” column becomes 3 different columns that can be interpreted as “Is in [country]”.</p>

<p>This transformation can also be applied to columns with integer values, which happens in the example for the “Num Of Products” column. Although this information is numerical, some intuition about the data helps here. We use a one-hot encoding for this column, because, when it comes to determining if the customer is going to stay or leave his bank, a customer who uses more of the bank’s products is probably different in nature from a customer who only uses one of the bank’s products.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TransformProcess</span> <span class="n">transformProcess</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TransformProcess</span><span class="o">.</span><span class="na">Builder</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
                <span class="o">.</span><span class="na">removeColumns</span><span class="o">(</span><span class="s">"Row Number"</span><span class="o">,</span> <span class="s">"Customer Id"</span><span class="o">,</span> <span class="s">"Surname"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">categoricalToOneHot</span><span class="o">(</span><span class="s">"Geography"</span><span class="o">,</span> <span class="s">"Gender"</span><span class="o">,</span> <span class="s">"Has Credit Card"</span><span class="o">,</span> <span class="s">"Is Active Member"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">integerToOneHot</span><span class="o">(</span><span class="s">"Num Of Products"</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Tenure"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">MinMax</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Age"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Standardize</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Credit Score"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Log2Mean</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Balance"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Log2MeanExcludingMin</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Estimated Salary"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Log2MeanExcludingMin</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">Schema</span> <span class="n">finalSchema</span> <span class="o">=</span> <span class="n">transformProcess</span><span class="o">.</span><span class="na">getFinalSchema</span><span class="o">();</span>
</code></pre></div></div>

<p>In choosing the appropriate normalization for the remaining columns, we are guided by the results of the analysis. As a rule of thumb, a <code class="highlighter-rouge">MinMax</code> normalization can be used for equally distributed values; a <code class="highlighter-rouge">Standardize</code> normalization is used for normally distributed values; and logarithmic normalization is often appropriate for values covering a wide range. This rule of thumb gives us the initial step, but in practice you should also consider other normalizations and see if they might work better for your problem. In this example, we are using a logarithmic normalization for the “Credit Score” value, although the data in the analysis shows the typical bell shape of a normal distribution.</p>

<p>Most normalization methods require statistical information about the data set to function. Here, too, the analysis we made earlier helps us. Since the analysis also knows the original schema, the <code class="highlighter-rouge">TransferProcess</code> can access the statistical information directly with the specified column name.</p>

<h3 id="vectorization">Vectorization</h3>

<p>The next step is to vectorize the data. Usually Deep Learning does not consider all training data at every training step, but only a fraction of it. This process is called mini-batching. Every full run through the data is called an epoch. We’d like that for each epoch, the mini-batches consist of different examples, since that helps in training a better model. For this reason, we instantiated the <code class="highlighter-rouge">InputSplit</code> at the beginning together with a <code class="highlighter-rouge">Random</code> object.</p>

<p>The size of the mini-batch, the so-called batch size, determines how many examples the model sees during each training step and thus also significantly influences the training regime. A larger batch size results in fewer mini-batches and thus fewer training steps in each epoch. At the same time, however, the model gets to see more data and may be able to find better patterns.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">batchSize</span> <span class="o">=</span> <span class="mi">80</span><span class="o">;</span>
</code></pre></div></div>

<p>We set the value for our case to 80, since we have 8000 examples in the training set and this leads to a clean cut of 100 mini-batches.</p>

<p>Using the just defined <code class="highlighter-rouge">TransformProcess</code> we create a new <code class="highlighter-rouge">RecordReader</code>, which will first read in the CSV data and then transform it immediately. As before, we initialize the record reader with the <code class="highlighter-rouge">InputSplit</code> that refers to our training data.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TransformProcessRecordReader</span> <span class="n">trainRecordReader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TransformProcessRecordReader</span><span class="o">(</span><span class="k">new</span> <span class="n">CSVRecordReader</span><span class="o">(),</span> <span class="n">transformProcess</span><span class="o">);</span>
<span class="n">trainRecordReader</span><span class="o">.</span><span class="na">initialize</span><span class="o">(</span><span class="n">inputSplit</span><span class="o">);</span>
</code></pre></div></div>

<p>Then a <code class="highlighter-rouge">DataSetIterator</code> is created, which reads the transformed data from the <code class="highlighter-rouge">RecordReader</code>, vectorizes it and takes care of building mini-batches. Since we want to solve a classification problem, we use the <code class="highlighter-rouge">classification</code> method to indicate in which column our label, i.e. the target value, can be found and how many possible classes there are. We will use this <code class="highlighter-rouge">DataSetIterator</code> to train our model.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RecordReaderDataSetIterator</span> <span class="n">trainIterator</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RecordReaderDataSetIterator</span><span class="o">.</span><span class="na">Builder</span><span class="o">(</span><span class="n">trainRecordReader</span><span class="o">,</span> <span class="n">batchSize</span><span class="o">)</span>
                <span class="o">.</span><span class="na">classification</span><span class="o">(</span><span class="n">finalSchema</span><span class="o">.</span><span class="na">getIndexOfColumn</span><span class="o">(</span><span class="s">"Exited"</span><span class="o">),</span> <span class="mi">2</span><span class="o">)</span>
                <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre></div></div>

<p>If you do not want to use DataVec, you can also implement the <code class="highlighter-rouge">DataSetIterator</code> interface yourself. However, this is usually only necessary if you have special needs for the pre-processing of your data or have special requirements when creating mini-batches.</p>

<h1 id="training-the-model">Training the model</h1>

<p>Before we can start training a model, we must first define what the model should look like. In contrast to many other machine learning methods, Deep Learning has a lot more options that have to be considered. You have to decide which architecture the network should use, how wide the individual layers should be, and which values many other hyperparameters should take. If you are lucky, there is a pre-trained model that can solve your own problem. Or maybe there is at least a paper describing a network architecture which you can use to orientate yourself.</p>

<h2 id="defining-the-structure">Defining the structure</h2>

<p>Basically, the network design depends on the specific problem you are dealing with. Convolutional layers are always useful where spatial contexts are interesting, e.g. in pictures. Recurrent layers are useful when sequences of data are to be processed and the order within the sequence is important. And Dense layers, also known as fully connected layers, are good if all existing data is to be considered at once.</p>

<p>Finding a good network architecture is a task that relies on experimentation. You have to try many ideas and conduct many experiments to find a really good model. As a guideline you can use the rule of thumb that you should start with simple models, i.e. models with few, narrow layers, and add complexity only slowly. If you can’t overfit your model, i.e. reduce the error to 0, on a fraction of your data, like a single mini-batch, then the model will probably not be able to learn anything, even if you give it more data.</p>

<p>For our example we will use a simple multi-layer model. First, we set a random seed, since model weights will be initialized randomly – in our case using the <code class="highlighter-rouge">XAVIER</code> initialization scheme. Setting a random seed is always recommended, especially if you have not yet fixed a model and its hyperparameters, as otherwise good results could simply happen by chance and these would no longer be reproducible. Next, the <code class="highlighter-rouge">TANH</code> activation function is set as a default for each layer. This is a practical shortcut, that allows us to avoid setting it on each layer individually. The updater used here is Adam with a learning rate of 0.001 and a L2 regularization of 0.0000316.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">MultiLayerConfiguration</span> <span class="n">config</span> <span class="o">=</span> <span class="k">new</span> <span class="n">NeuralNetConfiguration</span><span class="o">.</span><span class="na">Builder</span><span class="o">()</span>
                <span class="o">.</span><span class="na">seed</span><span class="o">(</span><span class="mh">0xC0FFEE</span><span class="o">)</span>
                <span class="o">.</span><span class="na">weightInit</span><span class="o">(</span><span class="n">WeightInit</span><span class="o">.</span><span class="na">XAVIER</span><span class="o">)</span>
                <span class="o">.</span><span class="na">activation</span><span class="o">(</span><span class="n">Activation</span><span class="o">.</span><span class="na">TANH</span><span class="o">)</span>
                <span class="o">.</span><span class="na">updater</span><span class="o">(</span><span class="k">new</span> <span class="n">Adam</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">learningRate</span><span class="o">(</span><span class="mf">0.001</span><span class="o">).</span><span class="na">build</span><span class="o">())</span>
                <span class="o">.</span><span class="na">l2</span><span class="o">(</span><span class="mf">0.0000316</span><span class="o">)</span>
                <span class="o">.</span><span class="na">list</span><span class="o">(</span>
                        <span class="k">new</span> <span class="n">DenseLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">nOut</span><span class="o">(</span><span class="mi">25</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
                        <span class="k">new</span> <span class="n">DenseLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">nOut</span><span class="o">(</span><span class="mi">25</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
                        <span class="k">new</span> <span class="n">DenseLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">nOut</span><span class="o">(</span><span class="mi">25</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
                        <span class="k">new</span> <span class="n">DenseLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">nOut</span><span class="o">(</span><span class="mi">25</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
                        <span class="k">new</span> <span class="n">DenseLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">().</span><span class="na">nOut</span><span class="o">(</span><span class="mi">25</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
                        <span class="k">new</span> <span class="n">OutputLayer</span><span class="o">.</span><span class="na">Builder</span><span class="o">(</span><span class="k">new</span> <span class="n">LossMCXENT</span><span class="o">()).</span><span class="na">nOut</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">activation</span><span class="o">(</span><span class="n">Activation</span><span class="o">.</span><span class="na">SOFTMAX</span><span class="o">).</span><span class="na">build</span><span class="o">()</span>
                <span class="o">)</span>
                <span class="o">.</span><span class="na">setInputType</span><span class="o">(</span><span class="n">InputType</span><span class="o">.</span><span class="na">feedForward</span><span class="o">(</span><span class="n">finalSchema</span><span class="o">.</span><span class="na">numColumns</span><span class="o">()</span> <span class="o">-</span> <span class="mi">1</span><span class="o">))</span>
                <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre></div></div>

<p>In this case, the model architecture consists of 5 DenseLayers each with 25 output units and one OutputLayer with 2 outputs. An OutputLayer itself is in principle also a DenseLayer, but the difference is in the loss function, which is also specified there. It calculates the deviation between what the model outputs during training and the label. With this deviation, the model is then adjusted to provide better results. The OutputLayer also sets a different activation function from the default <code class="highlighter-rouge">TANH</code> and uses a <code class="highlighter-rouge">SOFTMAX</code> activation instead. This ensures that the output of the model can be interpreted as a probability distribution, i.e. that each value is between 0 and 1 and the sum of all values is exactly 1.</p>

<p>Finally, <code class="highlighter-rouge">setInputType</code> is used to set what type of data the model will process (<code class="highlighter-rouge">feedForward</code>) and how many input columns the examples have. This will then automatically calculate the number of inputs for each layer, so we don’t have to specify it manually. For more complex models, this also adds the necessary adapters between two layer types automatically where needed.</p>

<p>All parameter values selected here are the result of some trial and error. For example, the <code class="highlighter-rouge">TANH</code> activation function has proven to be more effective for this problem, than the now more commonly used <code class="highlighter-rouge">RELU</code> activation function.</p>

<h2 id="training">Training</h2>

<p>The actual training is pretty simple compared with the effort that it takes to come up with a good model architecture. We first create a new model from the previously defined configuration, initialize it and then train it using the training set for 59 epochs, i.e. the training set is iterated over 59 times during the training. After some time, the training finishes and the trained model can be used.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">MultiLayerNetwork</span> <span class="n">model</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MultiLayerNetwork</span><span class="o">(</span><span class="n">config</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">init</span><span class="o">();</span>
<span class="n">model</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">trainIterator</span><span class="o">,</span> <span class="mi">59</span><span class="o">);</span>
</code></pre></div></div>

<p>The actual training always revolves around calling the <code class="highlighter-rouge">fit</code> method. DL4J has several variants to offer. The variant used in the example above accepts a <code class="highlighter-rouge">DataSetIterator</code> and an epoch number. If the epoch number is omitted, data is iterated over exactly once, i.e. the model is trained for one epoch. The last variant is that you iterate through the iterator yourself, and therefore also pass the next mini-batch to the <code class="highlighter-rouge">fit</code> method yourself.</p>

<p>Which of the different training methods you should use depends on what you want to do with the model between training sessions. For example, one could evaluate the model between each epoch, store different training states or manipulate the model in any other way.</p>

<h2 id="evaluation">Evaluation</h2>

<p>After the model has been trained, one also wants to evaluate how well it generalizes on data it has not yet seen. The test set is used for this purpose. To use the test set, we load it the same way as we did for the training set. In this case, the batch size is irrelevant for the result, so for simplicity’s sake we will use the same one as for the training set.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TransformProcessRecordReader</span> <span class="n">testRecordReader</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TransformProcessRecordReader</span><span class="o">(</span><span class="k">new</span> <span class="n">CSVRecordReader</span><span class="o">(),</span> <span class="n">transformProcess</span><span class="o">);</span>
<span class="n">testRecordReader</span><span class="o">.</span><span class="na">initialize</span><span class="o">(</span> <span class="k">new</span> <span class="n">FileSplit</span><span class="o">(</span><span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">"X:/Churn_Modelling/Test/"</span><span class="o">)));</span>
<span class="n">RecordReaderDataSetIterator</span> <span class="n">testIterator</span> <span class="o">=</span> <span class="k">new</span> <span class="n">RecordReaderDataSetIterator</span><span class="o">.</span><span class="na">Builder</span><span class="o">(</span><span class="n">testRecordReader</span><span class="o">,</span> <span class="n">batchSize</span><span class="o">)</span>
        <span class="o">.</span><span class="na">classification</span><span class="o">(</span><span class="n">finalSchema</span><span class="o">.</span><span class="na">getIndexOfColumn</span><span class="o">(</span><span class="s">"Exited"</span><span class="o">),</span> <span class="mi">2</span><span class="o">)</span>
        <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre></div></div>

<p>DL4J makes the evaluation of a model easy: it is usually sufficient to call the <code class="highlighter-rouge">evaluate</code> method on the model together with the test set. You get an <code class="highlighter-rouge">Evaluation</code> object, which is most often used to just display the evaluation summary somewhere. In our example, we write the summary to the console.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Evaluation</span> <span class="n">evaluate</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">evaluate</span><span class="o">(</span><span class="n">testIterator</span><span class="o">);</span>
<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">evaluate</span><span class="o">.</span><span class="na">stats</span><span class="o">());</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>========================Evaluation Metrics========================
 # of classes:    2
 Accuracy:        0,8710
 Precision:       0,8112
 Recall:          0,7257
 F1 Score:        0,5892
Precision, recall &amp; F1: reported for positive class (class 1 - "1") only
=========================Confusion Matrix=========================


    0    1
-----------
 1557   68 | 0 = 0
  190  185 | 1 = 1
Confusion matrix format: Actual (rowClass) predicted as (columnClass) N times
==================================================================
</code></pre></div></div>

<p>But, the evaluation object can also be used to access other evaluation metrics that where not shown in the summary by default. In our case, the <a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Matthews correlation coefficient</a> is particularly noteworthy, as it also considers the unequal distribution within the data, and thus shows that despite good accuracy, the predictive strength of this model is still somewhat limited.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">"MCC: "</span><span class="o">+</span><span class="n">evaluate</span><span class="o">.</span><span class="na">matthewsCorrelation</span><span class="o">(</span><span class="n">EvaluationAveraging</span><span class="o">.</span><span class="na">Macro</span><span class="o">));</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>MCC: 0.530128345214995
</code></pre></div></div>

<h2 id="tuning">Tuning</h2>
<p>Since training can take a long time, especially if you have a lot of data, you often don’t want to blindly belive that it will go well. This is especially important if you have not yet selected the optimal hyperparameters.</p>

<p>Hyperparameters are all parameters that define the exact form of the model and the training regime. There are two types of parameters: the parameters learned by the model, also called weights, and the hyperparameters specified by the user. Hyperparameters include, among others, the learning rate, the strength of regularization, the size of a mini-batch and also the size and number of layers in the network. Choosing good hyperparameter is still more art than science at the moment, but there are tools to help us.</p>

<p>First, we look at listeners which help by providing additional information during the training. In general, listeners are added to a model using the <code class="highlighter-rouge">addListeners</code> method. In the example two different listeners will be used. The <code class="highlighter-rouge">ScoreIterationListener</code> can be used without adding further dependencies and simply logs the training score, i.e. the value of the loss function on the current mini-batch. It is thus parameterized only with how often it should make an output. In our example, this happens every 50 iterations, i.e. after 50 mini-batches or twice per epoch.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="o">.</span><span class="na">addListeners</span><span class="o">(</span><span class="k">new</span> <span class="n">ScoreIterationListener</span><span class="o">(</span><span class="mi">50</span><span class="o">));</span>
</code></pre></div></div>

<p>Since it outputs the value of the loss function at the given iteration, we want that value to be decreasing.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener - Score at iteration 0 is 0.6176512682074273
[main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener - Score at iteration 50 is 0.417752781122097
[main] INFO org.deeplearning4j.optimize.listeners.ScoreIterationListener - Score at iteration 100 is 0.3902740254303334
</code></pre></div></div>

<p>The <code class="highlighter-rouge">StatsListener</code> is much more complex and is used together with a web interface. In order to use it another dependency is needed. Since the web interface is based on the Play Framework which uses Scala, the Scala version to be used must be specified in the artifact id. If you don’t have any other Scala-using dependencies, you can just use the one given here. At the moment the Scala versions 2.10 and 2.11 are supported.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="nt">&lt;dependency&gt;</span>
    <span class="nt">&lt;groupId&gt;</span>org.deeplearning4j<span class="nt">&lt;/groupId&gt;</span>
    <span class="nt">&lt;artifactId&gt;</span>deeplearning4j-ui_2.10<span class="nt">&lt;/artifactId&gt;</span>
    <span class="nt">&lt;version&gt;</span>${dl4j.version}<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>If the <code class="highlighter-rouge">StatsListener</code> is used as shown in the example, you get a hint in the log where the web interface can be found. Per default it can be found at <a href="http://127.0.0.1:9000">http://127.0.0.1:9000</a>. Like the <code class="highlighter-rouge">ScoreIterationListener</code>, it can also be parametrized to collect information only in certain intervals. In this example, we are again going with 50 iterations, or twice per epoch.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">UIServer</span> <span class="n">uiServer</span> <span class="o">=</span> <span class="n">UIServer</span><span class="o">.</span><span class="na">getInstance</span><span class="o">();</span>
<span class="n">StatsStorage</span> <span class="n">statsStorage</span> <span class="o">=</span> <span class="k">new</span> <span class="n">InMemoryStatsStorage</span><span class="o">();</span>
<span class="n">uiServer</span><span class="o">.</span><span class="na">attach</span><span class="o">(</span><span class="n">statsStorage</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">addListeners</span><span class="o">(</span><span class="k">new</span> <span class="n">StatsListener</span><span class="o">(</span><span class="n">statsStorage</span><span class="o">,</span> <span class="mi">50</span><span class="o">));</span>

<span class="n">model</span><span class="o">.</span><span class="na">fit</span><span class="o">(</span><span class="n">trainIterator</span><span class="o">,</span> <span class="mi">59</span><span class="o">);</span>
</code></pre></div></div>

<p>The web interface shows a lot of information that can be used to see whether the training is progressing well. A score-graph that tends to fall is particularly important. If it rises, the behavior is called divergent, i.e. the model does not only learn nothing, it becomes increasingly worse. In the screenshot you can see that the score for each mini-batch fluctuates, but still decreases on average, so you should not assume a divergence on the first ascent, but only when there is actually a continuing upward trend.</p>

<figure class="center">
<img src="/images/quickstart-with-dl4j/visualization.PNG" />
</figure>

<p>Another important information shown here is the Update to Parameter Ratio. The rule of thumb is that you should aim for a value around -3.0. This can be done by changing the learning rate. If the value is too high, e.g. -1.0, the learning rate should be reduced and if it is too low, e.g. -4.0, the learning rate should be increased.</p>

<p>As useful as the listeners are, you should also remember that they affect performance. If you want to train a model completely unattended, you should not slow down the process unnecessarily by collecting information that is never made visible.</p>

<p>Trying to manually figure out which hyperparameters provide the best training progress and the best result can quickly consume a lot of time. That’s where the next tool comes in: the <a href="https://github.com/deeplearning4j/deeplearning4j/tree/master/arbiter">Arbiter library</a> from DL4J supports an automated search for good hyperparameter combinations. For the advanced user it is definitely worth a look.</p>

<p><strong>Pro tip:</strong> When manually looking for a good L2 regularization value, start out with an order of magnitude value close to $\sqrt \frac{batchSize}{TotalExampleCount \times Epochs}$ , in this example using 100 epochs, this is $0.01 = 10^{-2}$ and start reducing it by orders of magnitude, i.e. go from $10^{-2}$ to $10^{-3}$ to $10^{-4}$ and so on. Once you find something that works, try bisecting the order of magnitude, i.e. go from $10^{-4}$ to $10^{-4.5}$ (= 0.0000316…). This is how the value in this example was found.</p>

<h2 id="saving">Saving</h2>

<p>Saving the model is also quite simple. By calling the <code class="highlighter-rouge">saveFile</code> method, the model is written to the specified file. By default, the Updater state is also saved. This is necessary if you want to continue training the saved model later. If you want to omit the Updater state, you can pass <code class="highlighter-rouge">false</code> as the second parameter to <code class="highlighter-rouge">saveFile</code>.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">File</span> <span class="n">modelSave</span> <span class="o">=</span> <span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">"X:/Churn_Modelling/model.bin"</span><span class="o">);</span>
<span class="n">model</span><span class="o">.</span><span class="na">save</span><span class="o">(</span><span class="n">modelSave</span><span class="o">);</span>
</code></pre></div></div>

<p>Usually, however, not only the model must be saved. If normalizations have been applied which depend on statistical information, then it is also necessary to save this information for future use, since you will also have to apply the exactly same normalizations on new data. You can add any other data into the model file. Note, however, that this will use Java’s serialization function. It is therefore appropriate to convert your data into the simplest possible format, before passing it to the <code class="highlighter-rouge">addObjectToFile</code> method, in order to have data that will still be loadable with newer versions.</p>

<p>In the example we save not only the model, but also the result of the analysis and the schema of the model input data.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ModelSerializer</span><span class="o">.</span><span class="na">addObjectToFile</span><span class="o">(</span><span class="n">modelSave</span><span class="o">,</span> <span class="s">"dataanalysis"</span><span class="o">,</span> <span class="n">analysis</span><span class="o">.</span><span class="na">toJson</span><span class="o">());</span>
<span class="n">ModelSerializer</span><span class="o">.</span><span class="na">addObjectToFile</span><span class="o">(</span><span class="n">modelSave</span><span class="o">,</span> <span class="s">"schema"</span><span class="o">,</span> <span class="n">finalSchema</span><span class="o">.</span><span class="na">toJson</span><span class="o">());</span>
</code></pre></div></div>

<h1 id="using-the-model">Using the Model</h1>

<p>Loading the model is as easy as saving it. We specify the file from which the data should be loaded and load the model and any additionally stored data.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">File</span> <span class="n">modelSave</span> <span class="o">=</span> <span class="k">new</span> <span class="n">File</span><span class="o">(</span><span class="s">"X:/Churn_Modelling/model.bin"</span><span class="o">);</span>
<span class="n">MultiLayerNetwork</span> <span class="n">model</span> <span class="o">=</span> <span class="n">ModelSerializer</span><span class="o">.</span><span class="na">restoreMultiLayerNetwork</span><span class="o">(</span><span class="n">modelSave</span><span class="o">);</span>
<span class="n">DataAnalysis</span> <span class="n">analysis</span> <span class="o">=</span> <span class="n">DataAnalysis</span><span class="o">.</span><span class="na">fromJson</span><span class="o">(</span><span class="n">ModelSerializer</span><span class="o">.</span><span class="na">getObjectFromFile</span><span class="o">(</span><span class="n">modelSave</span><span class="o">,</span> <span class="s">"dataanalysis"</span><span class="o">));</span>
<span class="n">Schema</span> <span class="n">targetSchema</span> <span class="o">=</span> <span class="n">Schema</span><span class="o">.</span><span class="na">fromJson</span><span class="o">(</span><span class="n">ModelSerializer</span><span class="o">.</span><span class="na">getObjectFromFile</span><span class="o">(</span><span class="n">modelSave</span><span class="o">,</span> <span class="s">"schema"</span><span class="o">));</span>
</code></pre></div></div>

<p>We assume that the data will come from a different source than the training data. So, we will not be able to reuse our CSVRecordReader. For this example, we are even going one step further and skip a record reader at all. Rather we will hard code it for the example, but putting a DTO with its getters in place would be just as easy.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">List</span> <span class="n">rawData</span> <span class="o">=</span> <span class="n">Arrays</span><span class="o">.</span><span class="na">asList</span><span class="o">(</span><span class="mi">26</span><span class="o">,</span> <span class="mi">8</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">547</span><span class="o">,</span> <span class="mf">97460.1</span><span class="o">,</span> <span class="mf">43093.67</span><span class="o">,</span> <span class="s">"France"</span><span class="o">,</span> <span class="s">"Male"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">);</span>
</code></pre></div></div>

<p>As with training, we start by defining a scheme and a TransformProcess. The big difference to training is that this time, we get the data in a different order and the unnecessary data does not even appear in the schema.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Schema</span> <span class="n">schema</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Schema</span><span class="o">.</span><span class="na">Builder</span><span class="o">()</span>
                <span class="o">.</span><span class="na">addColumnsInteger</span><span class="o">(</span><span class="s">"Age"</span><span class="o">,</span> <span class="s">"Tenure"</span><span class="o">,</span> <span class="s">"Num Of Products"</span><span class="o">,</span> <span class="s">"Credit Score"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnsDouble</span><span class="o">(</span><span class="s">"Balance"</span><span class="o">,</span> <span class="s">"Estimated Salary"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Geography"</span><span class="o">,</span> <span class="s">"France"</span><span class="o">,</span> <span class="s">"Germany"</span><span class="o">,</span> <span class="s">"Spain"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Gender"</span><span class="o">,</span> <span class="s">"Female"</span><span class="o">,</span> <span class="s">"Male"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Has Credit Card"</span><span class="o">,</span> <span class="s">"0"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">addColumnCategorical</span><span class="o">(</span><span class="s">"Is Active Member"</span><span class="o">,</span> <span class="s">"0"</span><span class="o">,</span> <span class="s">"1"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre></div></div>

<p>As a result, the TransformProcess has also to be somewhat different. This time there is no need to remove data, but it is necessary to put the columns back in the order they were used during the training, otherwise the model will not be able to use the data.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">String</span><span class="o">[]</span> <span class="n">newOrder</span> <span class="o">=</span> <span class="n">targetSchema</span><span class="o">.</span><span class="na">getColumnNames</span><span class="o">().</span><span class="na">stream</span><span class="o">().</span><span class="na">filter</span><span class="o">(</span><span class="n">it</span> <span class="o">-&gt;</span> <span class="o">!</span><span class="n">it</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="s">"Exited"</span><span class="o">)).</span><span class="na">toArray</span><span class="o">(</span><span class="n">String</span><span class="o">[]::</span><span class="k">new</span><span class="o">);</span>
</code></pre></div></div>

<p>That is the reason why we also saved the schema of our model input data. That way we can use it to reorder the new columns by name, rather then ensuring that they are provided in the correct order when converting the data into a record. To reorder the columns into the same order as was used in training, we use the stored schema, in which we remove the “Exited” column, since that is what we want to predict in production and is therefore not contained in our data any more.</p>

<p>Since the TransformProcess is still responsible for normalization, it also needs the previously saved analysis.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">TransformProcess</span> <span class="n">transformProcess</span> <span class="o">=</span> <span class="k">new</span> <span class="n">TransformProcess</span><span class="o">.</span><span class="na">Builder</span><span class="o">(</span><span class="n">schema</span><span class="o">)</span>
                <span class="o">.</span><span class="na">categoricalToOneHot</span><span class="o">(</span><span class="s">"Geography"</span><span class="o">,</span> <span class="s">"Gender"</span><span class="o">,</span> <span class="s">"Has Credit Card"</span><span class="o">,</span> <span class="s">"Is Active Member"</span><span class="o">)</span>
                <span class="o">.</span><span class="na">integerToOneHot</span><span class="o">(</span><span class="s">"Num Of Products"</span><span class="o">,</span> <span class="mi">1</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Tenure"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">MinMax</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Age"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Standardize</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Credit Score"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Log2Mean</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Balance"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Log2MeanExcludingMin</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">normalize</span><span class="o">(</span><span class="s">"Estimated Salary"</span><span class="o">,</span> <span class="n">Normalize</span><span class="o">.</span><span class="na">Log2MeanExcludingMin</span><span class="o">,</span> <span class="n">analysis</span><span class="o">)</span>
                <span class="o">.</span><span class="na">reorderColumns</span><span class="o">(</span><span class="n">newOrder</span><span class="o">)</span>
                <span class="o">.</span><span class="na">build</span><span class="o">();</span>
</code></pre></div></div>

<p>Now we convert our data into a record, transform it and vectorize the result to a format that is accepted by the model. Since we are using only a single record, it is practically a mini-batch of size 1.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">List</span><span class="o">&lt;</span><span class="n">Writable</span><span class="o">&gt;</span> <span class="n">record</span> <span class="o">=</span> <span class="n">RecordConverter</span><span class="o">.</span><span class="na">toRecord</span><span class="o">(</span><span class="n">schema</span><span class="o">,</span> <span class="n">rawData</span><span class="o">);</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">Writable</span><span class="o">&gt;</span> <span class="n">transformed</span> <span class="o">=</span> <span class="n">transformProcess</span><span class="o">.</span><span class="na">execute</span><span class="o">(</span><span class="n">record</span><span class="o">);</span>
<span class="n">INDArray</span> <span class="n">data</span> <span class="o">=</span> <span class="n">RecordConverter</span><span class="o">.</span><span class="na">toArray</span><span class="o">(</span><span class="n">transformed</span><span class="o">);</span>
</code></pre></div></div>

<p>As we want to perform a classification with our model, and its output is assigned a Softmax activation function, we can query the model with the <code class="highlighter-rouge">predict</code> method and get an integer array of answers.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span><span class="o">[]</span> <span class="n">labelIndices</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">predict</span><span class="o">(</span><span class="n">data</span><span class="o">);</span> <span class="c1">// = [0] = Will stay a customer</span>
</code></pre></div></div>

<p>We get an array, instead of just a single answer, because the model always assumes a batch of requests. Since we have made only one request in this case, we get an array with only one element back. It contains the index of the label as an answer. In our example, the index and label are identical, since we distinguish between 0 and 1. However, if we had more complex labels, we would still have to convert between the index and its meaning.</p>

<p>If you want to have not only the index of the label, e.g. because you want to see the full result of the model, or because you have not performed a classification, but a regression, you can use the <code class="highlighter-rouge">output</code> method.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">INDArray</span> <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="kc">false</span><span class="o">);</span> <span class="c1">// = [[    0.9844,    0.0156]]</span>
</code></pre></div></div>

<p>Please note, however, that the <code class="highlighter-rouge">output</code> method runs in training mode by default, i.e. regularization methods such as dropout are applied. You have to switch into inference mode by passing a second parameter set to <code class="highlighter-rouge">false</code>. Since the <code class="highlighter-rouge">output</code> method is also based on whole batches, the answer is also given in batch form.</p>

<p>Knowing we only have one result, we can convert the ND4J array into a simple double array using the <code class="highlighter-rouge">toDoubleVector</code> method.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">double</span><span class="o">[]</span> <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">data</span><span class="o">,</span> <span class="kc">false</span><span class="o">).</span><span class="na">toDoubleVector</span><span class="o">()</span> <span class="c1">// = [0.9843524098396301, 0.015647541731595993]</span>
</code></pre></div></div>

<p>If we had had more than one result, the <code class="highlighter-rouge">toDoubleMatrix</code> method would also be usable to get a double matrix, i.e. a two-dimensional double array.</p>

<h2 id="parallel-inference">Parallel Inference</h2>

<p>Models are not thread safe in DL4J, i.e. they cannot be used by multiple threads simultaneously (<em>Update:</em> Since 1.0.0-beta2 they are <code class="highlighter-rouge">synchronized</code>  so using them from different threads is possible, but will result in a serial execution). However, this can hardly be avoided in the context of web applications, for example. You could provide each thread with its own model, but this would quickly lead to requiring lots of memory, especially with complex models.</p>

<p>To solve this problem, there is the Parallel Inference module for DL4J, which takes requests from multiple threads, collects them for a short while, and then queries the model for all collected requests. Since the model works in parallel internally, the available resources are still fully utilized.</p>

<p>The module also requires adding another dependency.</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;dependency&gt;</span>
     <span class="nt">&lt;groupId&gt;</span>org.deeplearning4j<span class="nt">&lt;/groupId&gt;</span>
     <span class="nt">&lt;artifactId&gt;</span>deeplearning4j-parallel-wrapper<span class="nt">&lt;/artifactId&gt;</span>
     <span class="nt">&lt;version&gt;</span>${dl4j.version}<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
</code></pre></div></div>

<p>However, ultimately using it is simple. You create a <code class="highlighter-rouge">ParallelInference</code> instance, which in the simplest case only gets the model as a parameter. Then, this instance can be used instead of the model to get predictions from the model.</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ParallelInference</span> <span class="n">wrapped</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ParallelInference</span><span class="o">.</span><span class="na">Builder</span><span class="o">(</span><span class="n">model</span><span class="o">).</span><span class="na">build</span><span class="o">();</span>
<span class="n">INDArray</span> <span class="n">parOutput</span> <span class="o">=</span> <span class="n">wrapped</span><span class="o">.</span><span class="na">output</span><span class="o">(</span><span class="n">data</span><span class="o">);</span>
</code></pre></div></div>

<p>Since <code class="highlighter-rouge">ParallelInference</code> is always used for prediction, it is not necessary to activate inference by passing an additional parameter to its <code class="highlighter-rouge">output</code> method.</p>

<h1 id="beyond-the-quickstart">Beyond the quickstart</h1>

<p>DL4J offers many more features than those shown here. For example, there is also a multitude of pre-trained models in the model zoo. These are particularly interesting when used together with the transfer learning feature, which can be used to re-train the pre-trained models for new tasks similar to their original purpose.</p>

<p>DL4J also supports distributed learning with Spark. The basics shown in the article continue to apply for the most part. But, since distributed computing has its own overhead, the use is only worthwhile if you have a lot of data.</p>

<p>Reinforcement learning has been completely ignored in this blog post. But, the DL4J family of libraries also includes RL4J, which is based on DL4J and enables reinforcement learning with Java.</p>

<p>The dependencies given at the beginning cover many DL4J modules transitively. However, it is also possible to specify single modules as dependencies instead of <code class="highlighter-rouge">deeplearning4j-core</code>. This allows you to shave of a lot of size. This is particularly interesting when using DL4J on end devices such as smartphones.</p>

<h1 id="closing-remarks">Closing remarks</h1>

<p>This blog post gave an example of how to use the libraries in the Deeplearning4J family to go from data to training and using the model. The developers of Deeplearning4J also offer their own Github repository with many more examples, which can be found at <a href="https://github.com/deeplearning4j/dl4j-examples">https://github.com/deeplearning4j/dl4j-examples</a>. With the knowledge from this article, it should be easy to follow most of these examples.</p>

<p>If you have any further questions, there is also a gitter channel where you will usually find help quickly. It can be found at <a href="https://gitter.im/deeplearning4j/deeplearning4j">https://gitter.im/deeplearning4j/deeplearning4j</a>.</p>

      <footer class="entry-meta">
        <span class="entry-tags"><a href="https://www.dubs.tech/tags#dl4j" title="Pages tagged dl4j" class="tag"><span class="term">dl4j</span></a><a href="https://www.dubs.tech/tags#guide" title="Pages tagged guide" class="tag"><span class="term">guide</span></a></span>
        
        <span class="author vcard"><span class="fn">Paul Dubs</span></span>
        <div class="social-share">
  <ul class="socialcount socialcount-small inline-list">
    <li class="facebook"><a href="https://www.facebook.com/sharer/sharer.php?u=https://www.dubs.tech/guides/quickstart-with-dl4j/" title="Share on Facebook"><span class="count"><i class="fa fa-facebook-square"></i> Like</span></a></li>
    <li class="twitter"><a href="https://twitter.com/intent/tweet?text=https://www.dubs.tech/guides/quickstart-with-dl4j/" title="Share on Twitter"><span class="count"><i class="fa fa-twitter-square"></i> Tweet</span></a></li>
    <li class="googleplus"><a href="https://plus.google.com/share?url=https://www.dubs.tech/guides/quickstart-with-dl4j/" title="Share on Google Plus"><span class="count"><i class="fa fa-google-plus-square"></i> +1</span></a></li>
  </ul>
</div><!-- /.social-share -->

      </footer>
    </div><!-- /.entry-content -->
    <div class="read-more">
  <div class="read-more-header">
    <a href="/about" class="read-more-btn">About the Author</a>
  </div><!-- /.read-more-header -->
  <div class="read-more-content author-info">
    <h3>Paul Dubs</h3>
    <div class="author-container">
      <img class="author-img" src="https://www.dubs.tech/images/avatar.jpg" alt="Paul Dubs" />
      <div class="author-bio">Professional software developer for over 12 years. Passionate about creating maintainable solutions and helping people to learn.</div>
    </div>
    <div class="author-share">
      <ul class="list-inline social-buttons">
        
          <li><a href="https://github.com/treo" target="_blank"><i class="fa fa-github fa-fw"></i></a></li>
        
          <li><a href="https://www.linkedin.com/in/paul-dubs" target="_blank"><i class="fa fa-linkedin fa-fw"></i></a></li>
        
      </ul>
      
        <a aria-label="Follow @treo on GitHub" data-style="mega" href="https://github.com/treo" class="github-button">Follow @treo</a>
      
      <br>
      
        <a href="https://twitter.com/dot_treo" class="twitter-follow-button" data-show-count="false" data-size="large">Follow @dot_treo</a>
      
    </div>
  </div>
</div>

    
    <div class="read-more">
  
    <div class="read-more-header">
      <a href="https://www.dubs.tech/blog/benchmarking-nd4j-and-neanderthal-2/" class="read-more-btn">Read More</a>
    </div><!-- /.read-more-header -->
    <div class="read-more-content">
      <h3><a href="https://www.dubs.tech/guides/maven-essentials/" title="Maven: Essentials">Maven: Essentials</a></h3>
      <p>A quickstart guide for people that are required to use Maven right now. <a href="https://www.dubs.tech/guides/maven-essentials/">Continue reading</a></p>
    </div><!-- /.read-more-content -->
    
  
  <div class="read-more-list">
    
      <div class="list-item">
        <h4><a href="https://www.dubs.tech/blog/game-of-life-apl-nd4j-samediff/" title="Implementing Conway’s Game of Life with Tensor Math">Implementing Conway’s Game of Life with Tensor Math</a></h4>
        <span>Published on February 23, 2018</span>
      </div><!-- /.list-item -->
      
    
      <div class="list-item">
        <h4><a href="https://www.dubs.tech/blog/benchmarking-nd4j-and-neanderthal/" title="Benchmarking ND4J and Neanderthal">Benchmarking ND4J and Neanderthal</a></h4>
        <span>Published on June 26, 2018</span>
      </div><!-- /.list-item -->
      
    
  </div><!-- /.read-more-list -->
</div><!-- /.read-more -->
  </article>
</div><!-- /#main -->

<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script type="text/javascript">window.jQuery || document.write('<script type="text/javascript" src="https://www.dubs.tech/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script type="text/javascript" src="https://www.dubs.tech/assets/js/scripts.min.js"></script>
<script type="text/javascript" async defer id="github-bjs" src="https://buttons.github.io/buttons.js"></script>
<script type="text/javascript">!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>










<div class="footer-wrapper">
  <footer role="contentinfo">
    <span>&copy; 2019 Paul Dubs.</span>

  </footer>
</div><!-- /.footer-wrapper -->

</body>
</html>
